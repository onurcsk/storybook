{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# @title Imports\n",
        "from PIL import Image\n",
        "import IPython.display as display\n",
        "import requests\n",
        "from transformers import AutoProcessor, TFBlipForConditionalGeneration\n",
        "from io import BytesIO\n",
        "\n",
        "from evaluate import load\n",
        "import torch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "collapsed": true,
        "id": "lO4C8fPerVpw",
        "outputId": "2da2c591-04bb-415e-aad3-774ea30acead"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'evaluate'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-5c85eed92994>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mio\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mevaluate\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'evaluate'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*italicised text*# New section"
      ],
      "metadata": {
        "id": "stK0oLzcJuBE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "WEn6nw2AHrTm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Example Image\n",
        "# Example image URL\n",
        "image_url = \"https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcRzn-z0Nh-DBQQpd1l4fGgI9ouleVFBrSnsUw&s\"\n",
        "# Display image\n",
        "display.display(display.Image(url=image_url))"
      ],
      "metadata": {
        "id": "Z9PYGAa9sWRp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading processor and model"
      ],
      "metadata": {
        "id": "kE1KwkQpHzsh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "processor = AutoProcessor.from_pretrained(\"Salesforce/blip-image-captioning-large\")\n",
        "model = TFBlipForConditionalGeneration.from_pretrained(\"Salesforce/blip-image-captioning-large\")"
      ],
      "metadata": {
        "id": "Xco9MUjcrEuu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generating example output"
      ],
      "metadata": {
        "id": "I8sPsqemH_85"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image = Image.open(requests.get(image_url, stream=True).raw)\n",
        "# text = \"A picture of\"\n",
        "\n",
        "# inputs = processor(images=image, text=text, return_tensors=\"tf\")\n",
        "inputs = processor(images=image, return_tensors=\"tf\")\n",
        "\n",
        "outputs = model.generate(**inputs)\n",
        "outputs"
      ],
      "metadata": {
        "id": "2b7aKBMx1Nbw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Example Caption"
      ],
      "metadata": {
        "id": "4YDmWlXhIKMo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "caption = processor.decode(outputs[0], skip_special_tokens=True)\n",
        "caption"
      ],
      "metadata": {
        "id": "tDX5xdMtxQeD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Caption generation function"
      ],
      "metadata": {
        "id": "1VpRnCswIPhn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_captions(image_urls):\n",
        "    captions = []\n",
        "    for url in image_urls:\n",
        "        image = Image.open(BytesIO(requests.get(url, stream=True).content))\n",
        "        # text = \"A picture of\"\n",
        "        # inputs = processor(images=image, text=text, return_tensors=\"tf\")\n",
        "        inputs = processor(images=image, return_tensors=\"tf\")\n",
        "        outputs = model.generate(**inputs)\n",
        "        caption = processor.decode(outputs[0], skip_special_tokens=True)\n",
        "        captions.append(caption)\n",
        "    return captions"
      ],
      "metadata": {
        "id": "ZATQX8t100k6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Example batch creation of captions"
      ],
      "metadata": {
        "id": "6bYtJ91bIcG2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image_urls = [\n",
        "    \"https://cdn.cdnparenting.com/articles/2018/06/418806355-H-1024x700.jpg\",\n",
        "    \"https://littletikescommercial.com/wp-content/uploads/2020/12/Adventureland-Park-IA_199-scaled.jpg\",\n",
        "    \"https://www.kidstuffplaysystems.com/wp-content/uploads/2019/06/81110-Ring-trek.jpg\",\n",
        "    \"https://images.unsplash.com/photo-1621354598022-16599af1b8b2?q=80&w=870&auto=format&fit=crop&ixlib=rb-4.0.3&ixid=M3wxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8fA%3D%3D\"\n",
        "]"
      ],
      "metadata": {
        "id": "otiXl4vM1wLY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generate_captions(image_urls)"
      ],
      "metadata": {
        "id": "Xny9X98k105A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model evaluation"
      ],
      "metadata": {
        "id": "JbL7UByFQBTl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the WER metric\n",
        "wer = load(\"wer\")\n",
        "\n",
        "# Define the evaluation function\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    predicted = logits.numpy().argmax(-1)\n",
        "    decoded_labels = processor.batch_decode(labels, skip_special_tokens=True)\n",
        "    decoded_predictions = processor.batch_decode(predicted, skip_special_tokens=True)\n",
        "    wer_score = wer.compute(predictions=decoded_predictions, references=decoded_labels)\n",
        "    return {\"wer_score\": wer_score}\n",
        "\n",
        "# Example data: List of images and their corresponding true captions\n",
        "images = [\n",
        "    Image.open(requests.get(\"https://example.com/image1.jpg\", stream=True).raw),\n",
        "    Image.open(requests.get(\"https://example.com/image2.jpg\", stream=True).raw)\n",
        "]\n",
        "true_captions = [\"A picture of a cat\", \"A picture of a dog\"]\n",
        "\n",
        "# Prepare the inputs and labels\n",
        "inputs = processor(images=images, return_tensors=\"tf\", padding=True)\n",
        "labels = processor(text=true_captions, return_tensors=\"tf\", padding=True).input_ids\n",
        "\n",
        "# Generate predictions\n",
        "outputs = model(**inputs)\n",
        "logits = outputs.logits\n",
        "\n",
        "# Evaluate the model\n",
        "eval_pred = (logits, labels)\n",
        "metrics = compute_metrics(eval_pred)\n",
        "print(metrics)"
      ],
      "metadata": {
        "id": "pvbbQHPcQC8k"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}