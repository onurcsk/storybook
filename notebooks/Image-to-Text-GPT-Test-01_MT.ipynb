{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3c1644c",
   "metadata": {},
   "source": [
    "# Storybook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5309940d",
   "metadata": {},
   "source": [
    "## Install Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ebd57411",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.41.1-py3-none-any.whl.metadata (43 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.8/43.8 kB\u001b[0m \u001b[31m775.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting torch\n",
      "  Downloading torch-2.2.2-cp310-none-macosx_10_9_x86_64.whl.metadata (25 kB)\n",
      "Collecting filelock (from transformers)\n",
      "  Downloading filelock-3.14.0-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting huggingface-hub<1.0,>=0.23.0 (from transformers)\n",
      "  Downloading huggingface_hub-0.23.2-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/marius/.pyenv/versions/3.10.6/envs/storybook/lib/python3.10/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/marius/.pyenv/versions/3.10.6/envs/storybook/lib/python3.10/site-packages (from transformers) (24.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/marius/.pyenv/versions/3.10.6/envs/storybook/lib/python3.10/site-packages (from transformers) (6.0.1)\n",
      "Collecting regex!=2019.12.17 (from transformers)\n",
      "  Using cached regex-2024.5.15-cp310-cp310-macosx_10_9_x86_64.whl.metadata (40 kB)\n",
      "Requirement already satisfied: requests in /Users/marius/.pyenv/versions/3.10.6/envs/storybook/lib/python3.10/site-packages (from transformers) (2.32.2)\n",
      "Collecting tokenizers<0.20,>=0.19 (from transformers)\n",
      "  Downloading tokenizers-0.19.1-cp310-cp310-macosx_10_12_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting safetensors>=0.4.1 (from transformers)\n",
      "  Downloading safetensors-0.4.3-cp310-cp310-macosx_10_12_x86_64.whl.metadata (3.8 kB)\n",
      "Collecting tqdm>=4.27 (from transformers)\n",
      "  Using cached tqdm-4.66.4-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Users/marius/.pyenv/versions/3.10.6/envs/storybook/lib/python3.10/site-packages (from torch) (4.12.0)\n",
      "Collecting sympy (from torch)\n",
      "  Using cached sympy-1.12-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting networkx (from torch)\n",
      "  Downloading networkx-3.3-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: jinja2 in /Users/marius/.pyenv/versions/3.10.6/envs/storybook/lib/python3.10/site-packages (from torch) (3.1.4)\n",
      "Collecting fsspec (from torch)\n",
      "  Using cached fsspec-2024.5.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/marius/.pyenv/versions/3.10.6/envs/storybook/lib/python3.10/site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/marius/.pyenv/versions/3.10.6/envs/storybook/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/marius/.pyenv/versions/3.10.6/envs/storybook/lib/python3.10/site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/marius/.pyenv/versions/3.10.6/envs/storybook/lib/python3.10/site-packages (from requests->transformers) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/marius/.pyenv/versions/3.10.6/envs/storybook/lib/python3.10/site-packages (from requests->transformers) (2024.2.2)\n",
      "Collecting mpmath>=0.19 (from sympy->torch)\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Downloading transformers-4.41.1-py3-none-any.whl (9.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.1/9.1 MB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading torch-2.2.2-cp310-none-macosx_10_9_x86_64.whl (150.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.8/150.8 MB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.23.2-py3-none-any.whl (401 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m401.7/401.7 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached fsspec-2024.5.0-py3-none-any.whl (316 kB)\n",
      "Using cached regex-2024.5.15-cp310-cp310-macosx_10_9_x86_64.whl (281 kB)\n",
      "Downloading safetensors-0.4.3-cp310-cp310-macosx_10_12_x86_64.whl (415 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m415.8/415.8 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tokenizers-0.19.1-cp310-cp310-macosx_10_12_x86_64.whl (2.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m37.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached tqdm-4.66.4-py3-none-any.whl (78 kB)\n",
      "Downloading filelock-3.14.0-py3-none-any.whl (12 kB)\n",
      "Downloading networkx-3.3-py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m32.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached sympy-1.12-py3-none-any.whl (5.7 MB)\n",
      "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Installing collected packages: mpmath, tqdm, sympy, safetensors, regex, networkx, fsspec, filelock, torch, huggingface-hub, tokenizers, transformers\n",
      "Successfully installed filelock-3.14.0 fsspec-2024.5.0 huggingface-hub-0.23.2 mpmath-1.3.0 networkx-3.3 regex-2024.5.15 safetensors-0.4.3 sympy-1.12 tokenizers-0.19.1 torch-2.2.2 tqdm-4.66.4 transformers-4.41.1\n",
      "Collecting openai\n",
      "  Downloading openai-1.30.3-py3-none-any.whl.metadata (21 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/marius/.pyenv/versions/3.10.6/envs/storybook/lib/python3.10/site-packages (from openai) (4.4.0)\n",
      "Collecting distro<2,>=1.7.0 (from openai)\n",
      "  Downloading distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/marius/.pyenv/versions/3.10.6/envs/storybook/lib/python3.10/site-packages (from openai) (0.27.0)\n",
      "Collecting pydantic<3,>=1.9.0 (from openai)\n",
      "  Using cached pydantic-2.7.1-py3-none-any.whl.metadata (107 kB)\n",
      "Requirement already satisfied: sniffio in /Users/marius/.pyenv/versions/3.10.6/envs/storybook/lib/python3.10/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /Users/marius/.pyenv/versions/3.10.6/envs/storybook/lib/python3.10/site-packages (from openai) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /Users/marius/.pyenv/versions/3.10.6/envs/storybook/lib/python3.10/site-packages (from openai) (4.12.0)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/marius/.pyenv/versions/3.10.6/envs/storybook/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /Users/marius/.pyenv/versions/3.10.6/envs/storybook/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (1.2.1)\n",
      "Requirement already satisfied: certifi in /Users/marius/.pyenv/versions/3.10.6/envs/storybook/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/marius/.pyenv/versions/3.10.6/envs/storybook/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/marius/.pyenv/versions/3.10.6/envs/storybook/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Collecting annotated-types>=0.4.0 (from pydantic<3,>=1.9.0->openai)\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.18.2 (from pydantic<3,>=1.9.0->openai)\n",
      "  Using cached pydantic_core-2.18.2-cp310-cp310-macosx_10_12_x86_64.whl.metadata (6.5 kB)\n",
      "Downloading openai-1.30.3-py3-none-any.whl (320 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m320.6/320.6 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Using cached pydantic-2.7.1-py3-none-any.whl (409 kB)\n",
      "Using cached pydantic_core-2.18.2-cp310-cp310-macosx_10_12_x86_64.whl (1.9 MB)\n",
      "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Installing collected packages: pydantic-core, distro, annotated-types, pydantic, openai\n",
      "Successfully installed annotated-types-0.7.0 distro-1.9.0 openai-1.30.3 pydantic-2.7.1 pydantic-core-2.18.2\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers torch\n",
    "!pip install openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85fbc64a",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dcc046fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marius/.pyenv/versions/3.10.6/envs/storybook/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BlipProcessor, BlipForConditionalGeneration, GPT2Tokenizer, GPT2LMHeadModel\n",
    "from PIL import Image\n",
    "import requests\n",
    "from io import BytesIO\n",
    "import IPython.display as display"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4532eaed",
   "metadata": {},
   "source": [
    "### Load BLIP Model and Processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41042f29",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "blip_model_name = \"Salesforce/blip-image-captioning-large\"\n",
    "blip_processor = BlipProcessor.from_pretrained(blip_model_name)\n",
    "blip_model = BlipForConditionalGeneration.from_pretrained(blip_model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f19bf6e",
   "metadata": {},
   "source": [
    "## Define Function to Generate Caption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8da5aa3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_caption(image_url):\n",
    "    response = requests.get(image_url)\n",
    "    image = Image.open(BytesIO(response.content))\n",
    "\n",
    "    inputs = blip_processor(images=image, return_tensors=\"pt\")\n",
    "    outputs = blip_model.generate(**inputs)\n",
    "\n",
    "    caption = blip_processor.decode(outputs[0], skip_special_tokens=True)\n",
    "    return caption\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ad99c8",
   "metadata": {},
   "source": [
    "### Test Image Captioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6a49fa30",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcRzn-z0Nh-DBQQpd1l4fGgI9ouleVFBrSnsUw&s\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/onurcanskurt/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/transformers/generation/utils.py:1260: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caption: there is a small child playing with toy cars on the floor\n"
     ]
    }
   ],
   "source": [
    "# Example image URL\n",
    "image_url = \"https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcRzn-z0Nh-DBQQpd1l4fGgI9ouleVFBrSnsUw&s\"\n",
    "# Display image\n",
    "display.display(display.Image(url=image_url))\n",
    "# Generate caption\n",
    "caption = generate_caption(image_url)\n",
    "print(\"Caption:\", caption)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8567ba95",
   "metadata": {},
   "source": [
    "## Define Function to Generate Captions for Multiple Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f1e20e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_captions(image_urls):\n",
    "    captions = []\n",
    "    for url in image_urls:\n",
    "        caption = generate_caption(url)\n",
    "        captions.append(caption)\n",
    "    return captions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ba39fef",
   "metadata": {},
   "source": [
    "### Example Usage for Multiple Captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d48a32a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://cdn.cdnparenting.com/articles/2018/06/418806355-H-1024x700.jpg\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caption 1: several children are playing with a frisbee in a grassy field\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<img src=\"https://littletikescommercial.com/wp-content/uploads/2020/12/Adventureland-Park-IA_199-scaled.jpg\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caption 2: there are two children playing on a playground slide\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<img src=\"https://www.kidstuffplaysystems.com/wp-content/uploads/2019/06/81110-Ring-trek.jpg\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caption 3: there are many children playing on a playground structure\n"
     ]
    }
   ],
   "source": [
    "# Example list of image URLs\n",
    "image_urls = [\n",
    "    \"https://cdn.cdnparenting.com/articles/2018/06/418806355-H-1024x700.jpg\",\n",
    "    \"https://littletikescommercial.com/wp-content/uploads/2020/12/Adventureland-Park-IA_199-scaled.jpg\",\n",
    "    \"https://www.kidstuffplaysystems.com/wp-content/uploads/2019/06/81110-Ring-trek.jpg\"\n",
    "]\n",
    "\n",
    "# Generate captions\n",
    "captions = generate_captions(image_urls)\n",
    "for idx, caption in enumerate(captions):\n",
    "    display.display(display.Image(url=image_urls[idx]))\n",
    "    print(f\"Caption {idx+1}:\", caption)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6e62507a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['several children are playing with a frisbee in a grassy field',\n",
       " 'there are two children playing on a playground slide',\n",
       " 'there are many children playing on a playground structure']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "captions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96063808",
   "metadata": {},
   "source": [
    "## Load GPT-2 Model and Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2f424653",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt2_tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "gpt2_model = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec97cac",
   "metadata": {},
   "source": [
    "## Define Functions for Story Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9ec705ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_story_prompt(captions, theme):\n",
    "    combined_captions = \"\\n\".join(captions)\n",
    "    prompt = (\n",
    "        f\"Create a captivating and coherent children's story with the following elements:\\n\"\n",
    "        f\"Captions:\\n{combined_captions}\\n\"\n",
    "        f\"Theme: {theme}\\n\"\n",
    "        f\"Make sure the story is engaging and appropriate for children. \"\n",
    "        f\"Avoid repeating sentences and ensure the story flows naturally from one scene to the next. \"\n",
    "        f\"The story should be a fun, engaging, and imaginative adventure.\\n\"\n",
    "        f\"Story starts here: \"  # Clear indicator for the model to start story generation\n",
    "    )\n",
    "    return prompt\n",
    "\n",
    "def remove_repetitive_sentences(story):\n",
    "    sentences = story.split('. ')\n",
    "    unique_sentences = []\n",
    "    seen = set()\n",
    "\n",
    "    for sentence in sentences:\n",
    "        if sentence not in seen:\n",
    "            unique_sentences.append(sentence)\n",
    "            seen.add(sentence)\n",
    "\n",
    "    return '. '.join(unique_sentences)\n",
    "\n",
    "def generate_story_gpt2(captions, theme, word_count, temperature=0.7, top_p=0.9):\n",
    "    prompt = create_story_prompt(captions, theme)\n",
    "\n",
    "    inputs = gpt2_tokenizer.encode(prompt, return_tensors=\"pt\")\n",
    "    outputs = gpt2_model.generate(\n",
    "        inputs,\n",
    "        max_length=word_count + len(inputs[0]),  # Account for prompt length\n",
    "        num_return_sequences=1,\n",
    "        temperature=temperature,\n",
    "        top_p=top_p,\n",
    "        no_repeat_ngram_size=2,  # Helps to reduce repetition\n",
    "        pad_token_id=gpt2_tokenizer.eos_token_id  # Ensures padding uses the EOS token\n",
    "    )\n",
    "\n",
    "    story = gpt2_tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    # Remove the prompt from the generated text\n",
    "    story = story[len(prompt):].strip()\n",
    "    return remove_repetitive_sentences(story)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c64a80",
   "metadata": {},
   "source": [
    "## Generate a Story"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "86e60992",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/onurcanskurt/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:362: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.7` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/home/onurcanskurt/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:367: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Story: The story begins with two kids playing in the grass. They are both playing a game of dragon. One of the kids is playing the dragon and the other is trying to catch a dragon in his mouth. Both of them are trying their best to get the ball out of his throat. As the game progresses, the two boys are getting closer and closer to catching the Dragon. When the boys catch the Dragons, they are able to escape the area and get back to their parents. This is a great way to introduce the characters to each other and to your children as well. If you are a fan of dragons, you will love this story. It is also a good way for your kids to learn about the world of Dragon Ball Z. You will also love the fact that the children play with dragons. There are several different types of Dragons. Some are simple, some are complex, others are more complex. Each type of character has their own unique abilities and abilities. For example, if you have a Dragon that is very powerful, it will be able take out a lot of enemies. However, there are also many types that are very difficult to defeat. In this case, we will focus on the simple type. Dragon Balls are the most\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "# captions = [\n",
    "#     \"A little boy standing on a hill.\",\n",
    "#     \"The boy looking at a spaceship.\",\n",
    "#     \"The spaceship taking off into the sky.\",\n",
    "#     \"The boy inside the spaceship, smiling.\",\n",
    "#     \"The spaceship landing on Mars.\"\n",
    "# ]\n",
    "theme = \"Dragons\"\n",
    "word_count = 250  # Adjust based on age-appropriateness\n",
    "\n",
    "# Generate the story\n",
    "story = generate_story_gpt2(captions, theme, word_count)\n",
    "print(\"Generated Story:\", story)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af958e6e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
