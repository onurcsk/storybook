{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Frontend and uploads\n",
    "import streamlit as st\n",
    "\n",
    "## for Model 1: Image-to-Text / Captioning\n",
    "from PIL import Image\n",
    "from transformers import AutoProcessor, TFBlipForConditionalGeneration\n",
    "from io import BytesIO\n",
    "import IPython.display as display\n",
    "import requests\n",
    "import tensorflow as tf\n",
    "\n",
    "from evaluate import load\n",
    "import torch\n",
    "\n",
    "## for Model 2: Text-to-Text\n",
    "from google.cloud import aiplatform\n",
    "from vertexai import preview\n",
    "import vertexai\n",
    "import base64\n",
    "from vertexai.generative_models import GenerativeModel, Part, FinishReason\n",
    "import vertexai.preview.generative_models as generative_models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialisation of Vertex AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "aiplatform.init(\n",
    "    # your Google Cloud Project ID or number\n",
    "    # environment default used is not set\n",
    "    project='certain-cursor-419710',\n",
    "\n",
    "    # the Vertex AI region you will use\n",
    "    # defaults to us-central1\n",
    "    location='europe-west3',\n",
    "\n",
    "    # # Google Cloud Storage bucket in same region as location\n",
    "    # # used to stage artifacts\n",
    "    # staging_bucket='gs://my_staging_bucket',\n",
    "\n",
    "    # # custom google.auth.credentials.Credentials\n",
    "    # # environment default credentials used if not set\n",
    "    # credentials=my_credentials,\n",
    "\n",
    "    # # customer managed encryption key resource name\n",
    "    # # will be applied to all Vertex AI resources if set\n",
    "    # encryption_spec_key_name=my_encryption_key_name,\n",
    "\n",
    "    # # the name of the experiment to use to track\n",
    "    # # logged metrics and parameters\n",
    "    # experiment='Storybook_Gemini',\n",
    "\n",
    "    # # description of the experiment above\n",
    "    # experiment_description='Testing Storybook project with using Vertex AI for employ of Gemini 1.5'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Frontend Streamlit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st.set_page_config(\n",
    "    page_title=\"Image Captioning App\",\n",
    "    page_icon=\"ðŸ–¼ï¸\",\n",
    "    layout=\"centered\",\n",
    "    initial_sidebar_state=\"auto\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Model and Preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"model\" not in st.session_state:\n",
    "    st.session_state.model = TFBlipForConditionalGeneration.from_pretrained(\"Salesforce/blip-image-captioning-base\") # initialize the session state variable\n",
    "if \"processor\" not in st.session_state:\n",
    "    st.session_state.processor = AutoProcessor.from_pretrained(\"Salesforce/blip-image-captioning-base\") # initialize the session state variable\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upload images and create captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# App title\n",
    "st.title(\"Image Captioning App\")\n",
    "\n",
    "# Image upload feature\n",
    "uploaded_files = st.file_uploader(\"Upload up to 5 images\", type=[\"jpg\", \"jpeg\", \"png\"], accept_multiple_files=True)\n",
    "\n",
    "if uploaded_files:\n",
    "    if len(uploaded_files) > 5:\n",
    "        st.warning(\"You can only upload up to 5 images.\")\n",
    "    else:\n",
    "        captions = []\n",
    "        for uploaded_file in uploaded_files:\n",
    "            # Open the image\n",
    "            image = Image.open(uploaded_file)\n",
    "\n",
    "            # Display the image\n",
    "            # st.image(image, caption='Uploaded Image', use_column_width=True)\n",
    "\n",
    "            # Preprocess the image\n",
    "            # text = \"A picture of\"\n",
    "            # inputs = processor(images=image, text=text, return_tensors=\"tf\")\n",
    "            inputs = st.session_state.processor(images=image, return_tensors=\"tf\")\n",
    "\n",
    "            # Generate caption\n",
    "            # with tf.device('/CPU:0'):  # Use CPU to avoid potential issues with GPU\n",
    "            outputs = st.session_state.model.generate(**inputs)\n",
    "\n",
    "            # Decode and display the caption\n",
    "            caption = st.session_state.processor.decode(outputs[0], skip_special_tokens=True)\n",
    "            captions.append(caption)\n",
    "        st.write(f\"**Captions:** {captions}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Gemini Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lily was skipping through the meadow, her pink dress swirling around her. Suddenly, a flash of white caught her eye. A fluffy white rabbit with pink nose hopped out from behind a bush.\n",
      "\n",
      "\"Hello!\" Lily called out softly.\n",
      "\n",
      "The rabbit twitched its nose and hopped closer. Lily held out her hand, and the rabbit sniffed it curiously.\n",
      "\n",
      "\"You're so soft,\" Lily whispered, stroking its fur gently. The rabbit closed its eyes and nuzzled against her hand.\n",
      "\n",
      "Lily giggled and pulled out a juicy carrot from her basket. \"Would you like some of this?\"\n",
      "\n",
      "The rabbit took the carrot and munched happily, looking up at Lily with grateful eyes. \n",
      "\n",
      "Lily spent the rest of the afternoon playing with her new furry friend, feeling happy and content. As the sun began to set, the rabbit hopped away, leaving Lily with a smile on her face and a warm feeling in her heart. \n"
     ]
    }
   ],
   "source": [
    "def generate():\n",
    "  vertexai.init(project=\"certain-cursor-419710\", location=\"europe-west3\")\n",
    "  model = GenerativeModel(\n",
    "    \"gemini-1.5-flash-001\",\n",
    "  )\n",
    "  responses = model.generate_content(\n",
    "      [\"\"\"Write a harmless children story with less than 250 words. Include a white rabbit in it.\"\"\"],\n",
    "      generation_config=generation_config,\n",
    "      safety_settings=safety_settings,\n",
    "      stream=True,\n",
    "  )\n",
    "\n",
    "  for response in responses:\n",
    "    print(response.text, end=\"\")\n",
    "\n",
    "\n",
    "generation_config = {\n",
    "    \"max_output_tokens\": 8192,\n",
    "    \"temperature\": 1,\n",
    "    \"top_p\": 0.95,\n",
    "}\n",
    "\n",
    "safety_settings = {\n",
    "    generative_models.HarmCategory.HARM_CATEGORY_HATE_SPEECH: generative_models.HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,\n",
    "    generative_models.HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: generative_models.HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,\n",
    "    generative_models.HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: generative_models.HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,\n",
    "    generative_models.HarmCategory.HARM_CATEGORY_HARASSMENT: generative_models.HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,\n",
    "}\n",
    "\n",
    "generate()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "storybook_test_1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
