{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3c1644c",
   "metadata": {},
   "source": [
    "# Storybook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5309940d",
   "metadata": {},
   "source": [
    "## Install Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ebd57411",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /home/onurcanskurt/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (4.34.0)\n",
      "Requirement already satisfied: torch in /home/onurcanskurt/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (2.3.0)\n",
      "Requirement already satisfied: filelock in /home/onurcanskurt/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from transformers) (3.12.4)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /home/onurcanskurt/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from transformers) (0.16.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/onurcanskurt/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from transformers) (1.23.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/onurcanskurt/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/onurcanskurt/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/onurcanskurt/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from transformers) (2022.9.13)\n",
      "Requirement already satisfied: requests in /home/onurcanskurt/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from transformers) (2.28.1)\n",
      "Requirement already satisfied: tokenizers<0.15,>=0.14 in /home/onurcanskurt/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from transformers) (0.14.0)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /home/onurcanskurt/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from transformers) (0.3.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/onurcanskurt/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from transformers) (4.64.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/onurcanskurt/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: sympy in /home/onurcanskurt/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /home/onurcanskurt/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from torch) (2.8.7)\n",
      "Requirement already satisfied: jinja2 in /home/onurcanskurt/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /home/onurcanskurt/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from torch) (2022.10.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/onurcanskurt/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/onurcanskurt/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/onurcanskurt/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/onurcanskurt/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from torch) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/onurcanskurt/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from torch) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/onurcanskurt/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from torch) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/onurcanskurt/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from torch) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/onurcanskurt/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from torch) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/onurcanskurt/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from torch) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /home/onurcanskurt/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from torch) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/onurcanskurt/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: triton==2.3.0 in /home/onurcanskurt/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from torch) (2.3.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/onurcanskurt/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.2.140)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/onurcanskurt/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.0.9)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/onurcanskurt/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from jinja2->torch) (2.1.1)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/onurcanskurt/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from requests->transformers) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/onurcanskurt/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/onurcanskurt/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from requests->transformers) (1.26.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/onurcanskurt/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from requests->transformers) (2022.9.24)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/onurcanskurt/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n",
      "Requirement already satisfied: openai in /home/onurcanskurt/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (0.28.0)\n",
      "Requirement already satisfied: requests>=2.20 in /home/onurcanskurt/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from openai) (2.28.1)\n",
      "Requirement already satisfied: tqdm in /home/onurcanskurt/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from openai) (4.64.1)\n",
      "Requirement already satisfied: aiohttp in /home/onurcanskurt/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from openai) (3.9.5)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/onurcanskurt/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from requests>=2.20->openai) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/onurcanskurt/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from requests>=2.20->openai) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/onurcanskurt/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from requests>=2.20->openai) (1.26.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/onurcanskurt/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from requests>=2.20->openai) (2022.9.24)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/onurcanskurt/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from aiohttp->openai) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/onurcanskurt/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from aiohttp->openai) (22.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/onurcanskurt/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from aiohttp->openai) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/onurcanskurt/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from aiohttp->openai) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/onurcanskurt/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from aiohttp->openai) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /home/onurcanskurt/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages (from aiohttp->openai) (4.0.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers torch\n",
    "!pip install openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85fbc64a",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dcc046fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/onurcanskurt/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/transformers/utils/generic.py:311: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BlipProcessor, BlipForConditionalGeneration, GPT2Tokenizer, GPT2LMHeadModel\n",
    "from PIL import Image\n",
    "import requests\n",
    "from io import BytesIO\n",
    "import IPython.display as display\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4532eaed",
   "metadata": {},
   "source": [
    "### Load BLIP Model and Processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "41042f29",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-27 16:26:44.274146: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-27 16:26:44.659383: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-05-27 16:26:44.659402: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2024-05-27 16:26:44.717530: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-05-27 16:26:46.019162: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-27 16:26:46.019293: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-27 16:26:46.019303: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "blip_model_name = \"Salesforce/blip-image-captioning-large\"\n",
    "blip_processor = BlipProcessor.from_pretrained(blip_model_name)\n",
    "blip_model = BlipForConditionalGeneration.from_pretrained(blip_model_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f19bf6e",
   "metadata": {},
   "source": [
    "## Define Function to Generate Caption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8da5aa3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_caption(image_url):\n",
    "    response = requests.get(image_url)\n",
    "    image = Image.open(BytesIO(response.content))\n",
    "    \n",
    "    inputs = blip_processor(images=image, return_tensors=\"pt\")\n",
    "    outputs = blip_model.generate(**inputs)\n",
    "    \n",
    "    caption = blip_processor.decode(outputs[0], skip_special_tokens=True)\n",
    "    return caption\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ad99c8",
   "metadata": {},
   "source": [
    "### Test Image Captioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a49fa30",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'function' object has no attribute 'display'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m image_url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcRzn-z0Nh-DBQQpd1l4fGgI9ouleVFBrSnsUw&s\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Display image\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[43mdisplay\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdisplay\u001b[49m(display\u001b[38;5;241m.\u001b[39mImage(url\u001b[38;5;241m=\u001b[39mimage_url))\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Generate caption\u001b[39;00m\n\u001b[1;32m      6\u001b[0m caption \u001b[38;5;241m=\u001b[39m generate_caption(image_url)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'function' object has no attribute 'display'"
     ]
    }
   ],
   "source": [
    "# Example image URL\n",
    "image_url = \"https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcRzn-z0Nh-DBQQpd1l4fGgI9ouleVFBrSnsUw&s\"\n",
    "# Display image\n",
    "display.display(display.Image(url=image_url))\n",
    "# Generate caption\n",
    "caption = generate_caption(image_url)\n",
    "print(\"Caption:\", caption)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8567ba95",
   "metadata": {},
   "source": [
    "## Define Function to Generate Captions for Multiple Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f1e20e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_captions(image_urls):\n",
    "    captions = []\n",
    "    for url in image_urls:\n",
    "        caption = generate_caption(url)\n",
    "        captions.append(caption)\n",
    "    return captions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ba39fef",
   "metadata": {},
   "source": [
    "### Example Usage for Multiple Captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d48a32a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://cdn.cdnparenting.com/articles/2018/06/418806355-H-1024x700.jpg\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caption 1: several children are playing with a frisbee in a grassy field\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<img src=\"https://littletikescommercial.com/wp-content/uploads/2020/12/Adventureland-Park-IA_199-scaled.jpg\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caption 2: there are two children playing on a playground slide\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<img src=\"https://www.kidstuffplaysystems.com/wp-content/uploads/2019/06/81110-Ring-trek.jpg\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caption 3: there are many children playing on a playground structure\n"
     ]
    }
   ],
   "source": [
    "# Example list of image URLs\n",
    "image_urls = [\n",
    "    \"https://cdn.cdnparenting.com/articles/2018/06/418806355-H-1024x700.jpg\",\n",
    "    \"https://littletikescommercial.com/wp-content/uploads/2020/12/Adventureland-Park-IA_199-scaled.jpg\",\n",
    "    \"https://www.kidstuffplaysystems.com/wp-content/uploads/2019/06/81110-Ring-trek.jpg\"\n",
    "]\n",
    "\n",
    "# Generate captions\n",
    "captions = generate_captions(image_urls)\n",
    "for idx, caption in enumerate(captions):\n",
    "    display.display(display.Image(url=image_urls[idx]))\n",
    "    print(f\"Caption {idx+1}:\", caption)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6e62507a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['several children are playing with a frisbee in a grassy field',\n",
       " 'there are two children playing on a playground slide',\n",
       " 'there are many children playing on a playground structure']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "captions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96063808",
   "metadata": {},
   "source": [
    "## Load GPT-2 Model and Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2f424653",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt2_tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "gpt2_model = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec97cac",
   "metadata": {},
   "source": [
    "## Define Functions for Story Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9ec705ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_story_prompt(captions, theme):\n",
    "    combined_captions = \"\\n\".join(captions)\n",
    "    prompt = (\n",
    "        f\"Create a captivating and coherent children's story with the following elements:\\n\"\n",
    "        f\"Captions:\\n{combined_captions}\\n\"\n",
    "        f\"Theme: {theme}\\n\"\n",
    "        f\"Make sure the story is engaging and appropriate for children. \"\n",
    "        f\"Avoid repeating sentences and ensure the story flows naturally from one scene to the next. \"\n",
    "        f\"The story should be a fun, engaging, and imaginative adventure.\\n\"\n",
    "        f\"Story starts here: \"  # Clear indicator for the model to start story generation\n",
    "    )\n",
    "    return prompt\n",
    "\n",
    "def remove_repetitive_sentences(story):\n",
    "    sentences = story.split('. ')\n",
    "    unique_sentences = []\n",
    "    seen = set()\n",
    "    \n",
    "    for sentence in sentences:\n",
    "        if sentence not in seen:\n",
    "            unique_sentences.append(sentence)\n",
    "            seen.add(sentence)\n",
    "    \n",
    "    return '. '.join(unique_sentences)\n",
    "\n",
    "def generate_story_gpt2(captions, theme, word_count, temperature=0.7, top_p=0.9):\n",
    "    prompt = create_story_prompt(captions, theme)\n",
    "    \n",
    "    inputs = gpt2_tokenizer.encode(prompt, return_tensors=\"pt\")\n",
    "    outputs = gpt2_model.generate(\n",
    "        inputs, \n",
    "        max_length=word_count + len(inputs[0]),  # Account for prompt length\n",
    "        num_return_sequences=1, \n",
    "        temperature=temperature, \n",
    "        top_p=top_p,\n",
    "        no_repeat_ngram_size=2,  # Helps to reduce repetition\n",
    "        pad_token_id=gpt2_tokenizer.eos_token_id  # Ensures padding uses the EOS token\n",
    "    )\n",
    "    \n",
    "    story = gpt2_tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    # Remove the prompt from the generated text\n",
    "    story = story[len(prompt):].strip()\n",
    "    return remove_repetitive_sentences(story)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c64a80",
   "metadata": {},
   "source": [
    "## Generate a Story"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "86e60992",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/onurcanskurt/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:362: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.7` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/home/onurcanskurt/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:367: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Story: The story begins with two kids playing in the grass. They are both playing a game of dragon. One of the kids is playing the dragon and the other is trying to catch a dragon in his mouth. Both of them are trying their best to get the ball out of his throat. As the game progresses, the two boys are getting closer and closer to catching the Dragon. When the boys catch the Dragons, they are able to escape the area and get back to their parents. This is a great way to introduce the characters to each other and to your children as well. If you are a fan of dragons, you will love this story. It is also a good way for your kids to learn about the world of Dragon Ball Z. You will also love the fact that the children play with dragons. There are several different types of Dragons. Some are simple, some are complex, others are more complex. Each type of character has their own unique abilities and abilities. For example, if you have a Dragon that is very powerful, it will be able take out a lot of enemies. However, there are also many types that are very difficult to defeat. In this case, we will focus on the simple type. Dragon Balls are the most\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "# captions = [\n",
    "#     \"A little boy standing on a hill.\",\n",
    "#     \"The boy looking at a spaceship.\",\n",
    "#     \"The spaceship taking off into the sky.\",\n",
    "#     \"The boy inside the spaceship, smiling.\",\n",
    "#     \"The spaceship landing on Mars.\"\n",
    "# ]\n",
    "theme = \"Dragons\"\n",
    "word_count = 250  # Adjust based on age-appropriateness\n",
    "\n",
    "# Generate the story\n",
    "story = generate_story_gpt2(captions, theme, word_count)\n",
    "print(\"Generated Story:\", story)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af958e6e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
